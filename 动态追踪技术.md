# 动态追踪技术



----------


## [Choosing a Linux Tracer (2015)](http://www.brendangregg.com/blog/2015-07-08/choosing-a-linux-tracer.html)

> 一切的开始


----------



> 好文，需要仔细研究

- [动态追踪技术(一)：DTrace 导论](https://riboseyim.github.io/2016/11/26/DTrace/)
- [动态追踪技术(二)：strace+gdb 溯源 Nginx 内存溢出异常](https://mp.weixin.qq.com/s?__biz=MjM5MTY1MjQ3Nw==&mid=2651939588&idx=1&sn=35f71c5f88d1edf23cb2efc812ab8e6c&chksm=bd578c168a20050041c08618281691f0111f61c789097a69095933057618637fc54817815921#rd)
- [动态追踪技术(三) ：Tracing your kernel Functions!](https://riboseyim.github.io/2017/04/17/DTrace_FTrace/)
- [动态追踪技术(四)：基于 Linux bcc/BPF 实现 Go 程序动态追踪](https://riboseyim.github.io/2017/06/27/DTrace_bcc/)
- [动态追踪技术(五)：Welcome DTrace for Linux](https://riboseyim.github.io/2018/02/16/DTrace-Linux/)



----------


## [动态追踪技术漫谈](http://openresty.org/posts/dynamic-tracing/)

- **动态追踪技术**其实是一种后现代的**高级调试技术**。它可以帮助软件工程师以非常低的成本，在非常短的时间内，回答一些很难的关于软件系统方面的问题，从而更快速地排查和解决问题；
- **动态追踪技术**实际就能帮助我们实现这种**愿景**：最好能够不用摘机器下线，不用修改我们的代码或者配置，不用重启服务，在系统还在运行的时候，就把问题分析出来，定位出来，进而采取有针对性的解决办法。如果能做到这一点，那才是完美的，才能每晚都睡上一个好觉；
- **动态追踪技术是一种“`活体分析”`技术**；正在运行的软件系统本身其实就包含了绝大部分的宝贵信息，就可以被直接当作是一个实时变化的数据库来进行“查询”；我们可以在操作系统内核的帮助下，从外部发起一系列有针对性的查询，获取关于这个软件系统本身运行过程当中的许多第一手的宝贵的细节信息，从而指导我们的问题分析和性能分析等很多工作；
- **动态追踪技术通常是`基于操作系统内核`来实现的**；这种查询必须是足够安全的，是可以在生产系统上大量使用的；
- **在动态追踪里面一般是通过`探针`这样的机制来发起查询**；在软件系统的某一个层次，或者某几个层次上面，安置一些探针，然后我们会自己定义这些探针所关联的处理程序。追踪通常涉及两个纬度。一个是时间纬度，另一个则是空间纬度；
- **动态追踪技术允许我们使用`非侵入式`的方式**，不用去修改我们的操作系统内核，不用去修改我们的应用程序，也不用去修改我们的业务代码或者任何配置，就可以**快速高效地精确获取我们想要的信息**，第一手的信息，从而帮助定位我们正在排查的各种问题；
- **动态追踪技术一般是不需要目标应用来配合的**；各种基于动态追踪的分析工具的运行方式都是**一种“`热插拔`”的方式**，就是说，我们随时可以运行这个工具，随时进行采样，随时结束采样，而不用管目标系统的当前状态；
- **动态追踪的好处**就是，可以**实现“`随时随地，按需采集`”**。另外还有一个优势是它自身的性能损耗极小。仔细写出的调试工具对系统的极限性能的影响，通常在百分之五，甚至更低的比例以下，所以它一般不会对我们的最终用户产生可以观察到的性能影响；
- **DTrace 算是现代动态追踪技术的鼻祖**；创造 DTrace 这样一个非常高级的调试工具，来帮助他们在未来的工作当中避免把过多精力花费在愚蠢问题上面；DTrace 的`优势`是它采取了**跟操作系统内核紧密集成**的一种方式。D 语言的实现其实是一个**虚拟机（VM）**，有点像 Java 虚拟机（JVM）。它的一个好处在于 D 语言的运行时是**常驻内核**的；`缺点`是 D 语言缺乏循环结构，这导致许多针对目标进程中的复杂数据结构的分析工具很难编写；外一个较大的`缺点`是，DTrace 对于用户态代码的追踪支持比较弱，没有自动的加载用户态调试符号的功能，需要自己在 D 语言里面声明用到的用户态 C 语言结构体之类的类型；民间一些勇敢的工程师尝试的 DTrace 的 Linux 移植也一直距离生产级别的要求很远；
-  SystemTap 是目前 Linux 世界功能最强大，同时也是最实用的动态追踪框架；SystemTap 的`优点`是它有非常成熟的用户态调试符号的自动加载，同时也有循环这样的语言结构可以去编写比较复杂的探针处理程序，可以支持很多很复杂的分析处理；`缺点`：首先，它并**不是 Linux 内核的一部分**，就是说它并**没有与内核紧密集成**，所以它需要一直不停地追赶主线内核的变化。它通常是把它的“小语言”脚本动态编译成一个 Linux 内核模块的 C 源码，因此经常需要在线部署 C 编译器工具链和 Linux 内核的头文件，同时需要动态地加载这些编译出来的内核模块，以运行我们的调试逻辑。在我们的调试工具运行完毕之后，又存在动态卸载 Linux 内核模块的问题。出于这些原因，SystemTap 脚本的启动相比 DTrace 要慢得多；
- 无论是 DTrace 还是 SystemTap，其实都不支持编写完整的调试工具，因为它们都缺少方便的命令行交互的原语。所以我们才看到现实世界中许多基于它们的工具，其实最外面都有一个 Perl、Python 或者 Shell 脚本编写的包裹；
- 很多工程师在排查线上问题的时候，经常会自己在软件系统里面埋点；显然这种做法的成本是巨大的，不仅涉及业务系统本身的修改和维护成本的陡然提高，而且全量采集和存储大量的埋点信息的在线开销，也是非常可观的；埋点的方式主要存在两大问题，一个是“太多”的问题，一个是“太少”的问题；
- 另外一种暴力调试的做法也是我们某些运维工程师经常采用的，即把机器拉下线，然后设置一系列临时的防火墙规则，以屏蔽用户流量或者自己的监控流量，然后在生产机上各种折腾。这是很繁琐影响很大的过程。首先它会让机器不能再继续服务，降低了整个在线系统的总的吞吐能力。同时有些只有真实流量才能复现的问题，此时再也无法复现了；
- 具体实践：我经常会编写一些有针对性的工具，然后在一些关键的系统「穴位」上面放置一些经过仔细安排的探针。这些探针会采集各自的信息，同时调试工具会把这些信息汇总起来输出到终端。用这种方式我可以在某一台机器或某几台机器上面，通过采样的方式，很快地得到我想要的关键信息，从而快速地回答一些非常基本的问题，给后续的调试工作指明方向；
- 案例：
    - 第一个例子是，我使用基于 SystemTap 的火焰图工具分析我们线上的 Nginx 进程，结果发现有相当一部分 CPU 时间花费在了一条非常奇怪的代码路径上面；
    - 第二个例子是，很少量的请求存在延时较长的问题，即所谓的“长尾请求”；
    - 第三个例子是，我们曾注意到某一个机房的机器存在比例明显高于其他机房的网络超时的问题，但也只有 1% 的比例；
    - 还有一个例子是，我们曾经通过火焰图在 Nginx 进程里观察到文件的打开和关闭操作占用了较多的 CPU 时间，于是我们很自然地启用了 Nginx 自身的文件句柄缓存配置，但是优化效果并不明显；
    - 最后一个例子是，我们在某一次上线操作之后，在线上最新的火焰图中观察到正则表达式的编译操作占用了很多 CPU 时间，但其实我们已经在线上启用了正则编译结果的缓存；
- `火焰图`就像是给一个软件系统拍的 X 光照片，可以很自然地把时间和空间两个维度上的信息融合在一张图上，以非常直观的形式展现出来，从而**反映系统在性能方面的很多定量的统计规律**；
    - on-CPU 时间维度：看程序运行在 CPU 上的时间在所有代码路径上的分布；
    - off-CPU 时间维度：看某一个进程不运行在任何 CPU 上的时间；off-CPU 时间一般是这个进程因为某种原因处于休眠状态，比如说在等待某一个系统级别的锁，或者被一个非常繁忙的进程调度器（scheduler）强行剥夺 CPU 时间片。这些情况都会导致这个进程无法运行在 CPU 上，但是仍然花费很多的挂钟时间；在分析 off-CPU 火焰图时需要注意，多线程的程序因为线程同步方面的原因，off-CPU 图上会有很多噪音，容易掩盖真正有趣的那些部分；
        - 分析系统锁方面的开销（比如 sem_wait 这样的系统调用）
        - 某些阻塞的 I/O 操作（例如 open、read 之类）
        - 分析进程或线程之间争用 CPU 的问题
- **推荐一种所谓的`小步推进、连续求问`的策略**：也就是说我们并不指望一下编写一个很庞大很复杂的调试工具，一下子采集到所有可能需要的信息，从而一下子解决掉最终的问题。相反，我们会把最终问题的假设，分解成一系列的小假设，然后逐步求索，逐步验证，不断确定会修正我们的方向，不断地调整我们的轨迹和我们的假设，以接近最终的问题。这样做有一个好处是，每一个步骤每一个阶段的工具都可以足够的简单，那么这些工具本身犯错的可能性就大大降低；简单工具的另一大好处是，在采样过程当中对生产系统产生的开销也会相对较小，毕竟引入的探针数目较少，每个探针的处理程序也不会有太多太复杂的计算。这里的每一个调试工具都有自己的针对性，都可以单独使用，那么这些工具在未来得到复用的机会也大大提高；
- 值得一提的是，这里我们**拒绝所谓的“`大数据`”的调试做法**。即我们并不会去尝试一下子采集尽可能全的信息和数据。相反，我们在每一个阶段每一个步骤上只采集我们当前步骤真正需要的信息；
- **对于非常小频率发生的线上事件，我们通常会采用“`守株待兔`”的做法**，也就是说我们会设一个阈值或其他筛选条件，坐等有趣的事件被我们的探针捕获到；
- 鼓励工程师不断的深入学习的工具才是有前途的好工具；


----------


> 下面的其他内容，均为基于该文章的知识点展开


----------


## Dtrace 相关

以下内容取自 [dtrace.org](http://dtrace.org/blogs/about/)

> `DTrace` is a performance analysis and troubleshooting tool that is included by default with various operating systems, including Solaris, Mac OS X and FreeBSD. A Linux port is in development.
>
> `DTrace` instruments all software.
>
> Not just user-level software, including applications, databases and webservers, but also the operating system kernel and device drivers. The name is short for **Dynamic Tracing**: an instrumentation technique pioneered by `DTrace` which dynamically patches live running instructions with instrumentation code. The `DTrace` facility also supports **Static Tracing**: where user-friendly trace points are added to code and compiled-in before deployment.
>
> `DTrace` provides a language, ‘D’, for writing `DTrace` scripts and one-liners. The language is like C and awk, and provides powerful ways to filter and summarize data in-kernel before passing to user-land. This is an important feature that enables `DTrace` to be used in performance-sensitive production environments, as it can greatly reduce the overhead of gathering and presenting data.

![](http://dtrace.org/blogs/wp-content/uploads/2011/11/dtracepony.png)

![](http://dtrace.org/blogs/wp-content/uploads/2012/11/dtrace_pony_xray.png)

以下内容取自 [DTraceToolkit](http://www.brendangregg.com/dtracetoolkit.html)

> The `DTraceToolkit` is a collection of useful documented `DTrace` scripts, some of which originated from my original page on DTrace Tools. There are over 200 scripts in the `DTraceToolkit`, and each has a man page and an file of example output.

![](http://www.brendangregg.com/DTraceToolkit/Bin099_04c.png)

以下内容取自 [DTrace Tools](http://www.brendangregg.com/dtrace.html)

> The following are open source tools and examples that use `DTrace`, an implementation of **dynamic tracing** that is available in different OSes (Solaris, Mac OS X, FreeBSD, ...). `DTrace` helps troubleshoot problems on servers by providing new detailed views of application and system internals, to a level that was previously difficult or impossible to access. It provides a language to write `DTrace` scripts that is similar to C and awk and is event based. For a longer summary, see the wikipedia [`DTrace`](https://en.wikipedia.org/wiki/DTrace) entry.


----------


## ptrace

以下内容取自 [ptrace man(2)](http://man7.org/linux/man-pages/man2/ptrace.2.html)

> The `ptrace()` system call provides a means by which one process (the "tracer") may observe and control the execution of another process (the "tracee"), and examine and change the tracee's memory and registers.  It is primarily used to implement breakpoint debugging and system call tracing.

## utrace

以下内容取自 [wiki/utrace](https://sourceware.org/systemtap/wiki/utrace)

> NOTE: `utrace` is deprecated. Linux kernels with version >= 3.5 (2012-July) contain most or all of the infrastructure necessary for user-space probing, without these earlier `utrace` patches.

以下内容取自《[Introducing utrace](https://lwn.net/Articles/224772/)》

> The interface for tracing programs under Linux is the `ptrace()` system call. It is used primarily by debuggers, but there are other applications too; User-mode Linux can use `ptrace()`, for example. The interface gets the job done, but there are few system calls which endure more criticism. The list of `ptrace()` shortcomings is long, its interface is difficult for user-space developers to use and for kernel-space developers to maintain, it is inefficient, and it has been the source of more than one security problem over the years. Still, `ptrace()` endures; it is part of the user-space API and there is nothing better available.
>
> Soon there may be a better alternative, in the form of the "`utrace`" patch (by Roland McGrath) which is currently in the `-mm` tree. `Utrace` replaces `ptrace()` entirely, while maintaining the same interface to user space. As such, it is a useful cleanup of a difficult system call. The real value of `utrace`, however, is likely to be seen in new tracing interfaces in the future.


最初 Red Hat 公司的工程师为 Linux 内核准备了一个所谓的 `utrace` 的补丁，用来支持用户态的动态追踪技术。这是 `SystemTap` 这样的框架最初仰赖的基础。在漫长的岁月里，Red Hat 家族的 Linux 发行版都默认包含了这个 `utrace` 补丁，比如 RHEL、CentOS 和 Fedora 之类。在那段 `utrace` 主导的日子里，`SystemTap` 只在 Red Hat 系的操作系统中有意义。这个 `utrace` 补丁最终也未能合并到主线版本的 Linux 内核中，它被另一种折衷的方案所取代。

## kprobes

以下内容取自《[An introduction to KProbes](https://lwn.net/Articles/132196/)》

> `KProbes` is a debugging mechanism for the Linux kernel which can also be used for monitoring events inside a production system. You can use it to weed out performance bottlenecks, log specific events, trace problems etc. KProbes was developed by IBM as an underlying mechanism for another higher level tracing tool called DProbes. DProbes adds a number of features, including its own scripting language for the writing of probe handlers. However, only KProbes has been merged into the standard kernel.

Linux 主线版本很早就拥有了 `kprobes` 这种机制，可以动态地在指定的内核函数的入口和出口等位置上放置探针，并定义自己的探针处理程序。


## uprobes

以下内容取自《[Uprobes in 3.5](https://lwn.net/Articles/499190/)》

> `Uprobes` is a kernel patch with a long story and many contentious discussions behind it. This code has its roots in `utrace`, a user-space tracing and debugging API that was first [covered here](https://lwn.net/Articles/224772/) in early 2007. `Utrace` ran into various types of opposition (only partly related to its own origin in `SystemTap`) and has never been merged, but a piece of it lives on in the form of `uprobes`, which is charged with the placement of probes into user-space code. After several mailing-list rounds of its own, `uprobes` was finally merged for the 3.5 kernel development cycle. Just how this facility will be used remains to be seen, however.

用户态的动态追踪支持姗姗来迟，经历了无数次的讨论和反复修改。从官方 Linux 内核的 3.5 这个版本开始，引入了基于 inode 的 `uprobes` 内核机制，可以安全地在用户态函数的入口等位置设置动态探针，并执行自己的探针处理程序。

## uretprobes

以下内容取自《[uretprobes: return probes implementation](https://lwn.net/Articles/543924/)》

> this is core implementation of the `uretprobes`. This enables a breakpoint on function's return for the tools such as `perf`.
>
> Introduce additional handler* for `uprobe` consumer that makes possible the distinguish `uprobe` from `uretprobe`. Note, behind every `uretprobe` a regular `uprobe` with return probe handler(`rp_handler`). Once hit the `uprobe` that has `rp_handler`, we hijack the return address of the probed function and replacing
it with the address of trampoline. Trampoline is the preallocated page in probed task's xol area that filled with breakpoint opcode. In turn, when the return breakpoint is hit, invoke the `rp_handler`.

再后来，从 3.10 的内核开始，又融合了所谓的 `uretprobes` 这个机制，可以进一步地在用户态函数的返回地址上设置动态探针。`uprobes` 和 `uretprobes` 加在一起，终于可以取代 `utrace` 的主要功能。`utrace` 补丁从此也完成了它的历史使命。而 `SystemTap` 现在也能在较新的内核上面，自动使用 `uprobes` 和 `uretprobes` 这些机制，而不再依赖于 `utrace` 补丁。


## BPF

以下内容取自《[Linux Socket Filtering aka Berkeley Packet Filter (BPF)](https://www.kernel.org/doc/Documentation/networking/filter.txt)》

> **Linux Socket Filtering** (`LSF`) is derived from the **Berkeley Packet Filter**. Though there are some distinct differences between the BSD and Linux Kernel filtering, but when we speak of `BPF` or `LSF` in Linux context, we mean the very same mechanism of filtering in the Linux kernel.
>
> `BPF` allows a user-space program to **attach** a filter onto any socket and allow or disallow certain types of data to come through the socket. `LSF` follows exactly the same filter code structure as BSD's `BPF`, so referring to the BSD bpf.4 manpage is very helpful in creating filters.
> 
> On Linux, `BPF` is much simpler than on BSD. One does not have to worry about devices or anything like that. You simply create your filter code, send it to the kernel via the `SO_ATTACH_FILTER` option and if your filter code passes the kernel check on it, you then immediately begin filtering data on that socket.
> 
> You can also **detach** filters from your socket via the `SO_DETACH_FILTER` option. This will probably not be used much since when you close a socket that has a filter on it the filter is automagically removed. The other less common case may be adding a different filter on the same socket where you had another filter that is still running: the kernel takes care of removing the old one and placing your new one in its place, assuming your filter has passed the checks, otherwise if it fails the old filter will remain on that socket.
> 
> `SO_LOCK_FILTER` option allows to lock the filter attached to a socket. Once set, a filter cannot be removed or changed. This allows one process to **setup** a socket, **attach** a filter, **lock** it then **drop** privileges and be assured that the filter will be kept until the socket is closed.
> 
> The biggest user of this construct might be `libpcap`. Issuing a high-level filter command like `tcpdump -i em1 port 22` passes through the `libpcap` internal compiler that generates a structure that can eventually be loaded via `SO_ATTACH_FILTER` to the kernel. `tcpdump -i em1 port 22 -ddd` displays what is being placed into this structure.
> 
> Although we were only speaking about sockets here, `BPF` in Linux is used in many more places. There's `xt_bpf` for `netfilter`, `cls_bpf` in the kernel `qdisc` layer, `SECCOMP-BPF` (SECure COMPuting [1]), and lots of other places such as team driver, PTP code, etc where `BPF` is being used.


## eBPF

以下内容取自《[eBPF: One Small Step](http://www.brendangregg.com/blog/2015-05-15/ebpf-one-small-step.html)》

以下内容取自《[Linux Enhanced BPF (eBPF) Tracing Tools](http://www.brendangregg.com/ebpf.html)》



