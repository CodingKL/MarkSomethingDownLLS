# 面试问题集锦

## 曾经使用过的面试题

### DevOps 类

- 基于 ansible 进行灰度发布过程中，出现部分失败的情况时如何处理，可能会有何种影响？
- 为什么不统一 zabbix、collectd 等监控系统，而是同时在使用？使用上的区别是什么？
- 监控系统的精度如何？如何取舍？
- 基于 opentracing 的跟踪系统，调用链耗时统计的工作原理？
- 调用链路跟踪的最后一公里问题（即到 mysql/redis/mq 等组件的最后一条）
- 容器管理平台的管理内容都有哪些？如何管理？和 k8s 的关系？
- 反向监测系统中的“二次监测”和“反向监测”的目的，以及网络完全断开的特定场景下的问题？


### 数据库和缓存类

- MySQL 数据库复制原理，以及格式是怎样的？
- MySQL master-master 同步场景下，自增索引（auto-increment）冲突问题如何解决的？
- MySQL 数据复制延迟如何解决的？
- Redis 数据 sharding 如何做？如何解决数据迁移问题？
- 可以从哪些方面优化 db 及缓存，提升系统响应速度？
- 什么情况下用缓存？


### 基础技能类

- docker 的监控如何做？
- 比较一下 Golang 里 buffered channel 和 unbuffered channel 的异同，各自的应用场景
- 从单体应用到微服务的改造过程中，参与的主要内容是？难点是？ 
- 服务发现如何做？
- dapper 的大概结构


### 系统分析类

- 第三方服务超时对应用的影响？如何判断问题？
- 同时使用 F5 和 nginx 的原因，以及解决的问题？
- 服务器侧出现大量 TIME_WAIT 或 CLOSE_WAIT 时，会有什么影响，可能有什么问题？
- 高并发 tcp 服务器在连接超标超负荷状态下会有什么表现，发生什么问题？
- 处理线上故障的一般流程？


### 应用设计类

- 连接池的目的、设计？
- 如何存应用的 secrets ? 
- 用 Golang 实现一个简单的 worker 队列系统
- 整个大的 PHP 服务在迁移到 Golang 的过程中，整个迁移过程是怎么样的，遇到了哪些坑
- 敏感词过滤系统是怎么设计的，如何做到快速高效的匹配
- 微服务之间的心跳的实现方式，以及实现的功能？
- 设计一个适用于 SASS 平台 IAM 系统
- 微服务是怎么做 tracing 的？


### 杂项

- 为啥要离开xxx公司？对自己的规划是啥？会怎么选公司？平时的爱好是啥？


------


## Docker & k8s & 微服务

### Pod 的 ip 地址是由谁分配的？Service 的 cluster ip 是由谁分配的？分别有什么特点？

> - Pod 的 ip 地址是由 Docker Daemon 根据 docker0 网桥的 ip 地址段进行分配的；
> - Service 的 cluster ip 是由 k8s 系统动态分配的，是虚拟 ip 地址；
> - Service 的 cluster ip 在 Service 被创建时分配，在 Service 销毁前，不会发生变化；
> - Pod 的 ip 地址和 Pod 的生命周期保持一致；
> - Service 的 cluster ip 默认只能在 k8s 系统内部访问，即其他 Pod 都可以无障碍的访问；


### Endpoint 与 Service 和 Pod 的关系是？

> - Endpoint 对象有由 podIP 和容器需要监听的 port 构成（当容器中只存在一个服务时，可以直接将其看做 podPort）；
> - Endpoint 用于描述（建立）Service 与 Pod 之间的对应关系；
> - Endpoint 对象随 Pod 的创建、销毁进行更新；


### k8s 对外提供服务的 Service type 有哪些？区别和特点？

> - NodPort: 系统会在 k8s 集群中的每个 node 上打开一个主机上的真实端口，进而确保能够访问到 node 的客户端，就能访问到该 Service ；
> - LoadBalancer: 当云服务商支持外接负载均衡器时，可以使用（出现了 ingress 概念）；


### 同一个 Pod 内的多个容器是如何相互通信的？

> 可以直接通过 localhost 进行通信，


### 副本控制器 RC 的常用模式有哪些？

> - 重新调度 rescheduling
> - 弹性伸缩 scaling
> - 滚动更新 rolling-update


### 性伸缩 scaling 和滚动更新 rolling-update 的实现

> - 基于 RC 实现



### 微服务架构有哪些特征？

> - 服务组件化
> - 划分为围绕业务能力组织的服务
> - 是产品不是服务
> - 智能端点和哑管道
> - 去中心化治理
> - 去中心化数据管理
> - 基础设施自动化
> - 为失效设计(断路器，吞吐量，时延)
> - 进化式设计(强可替代性)


### 微服务的核心模式？

> - 服务注册与发现
> - 配置中心(解决多套环境配置问题)
> - api 网关(存在的价值：屏蔽客户端对服务拆分的感知，屏蔽由服务实例位置给客户端带来的影响，提供最优api，降低请求或往返交互次数，统一客户端访问入口)
> - 熔断器(可以防止应用程序不断尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费cpu时间去等待超时产生)
> - 分布式追踪(问题：分散在各个服务器上的日志如何处理？出错后如何定位？如何跟踪业务流的处理顺序和结果)




------


## TCP

### A 进程通过 tcp 向另一台机器上的 B 进程发送了字符串 "hello" ，之后收到 tcp 的 ACK ，问：A 能否肯定进程 B 收到了该字符串，为什么？

### 如何尽量避免由于发生机器意外掉电导致的缓冲区数据丢失？

### tcp 协议中 PSH 标志的用途？如何设置？

http://blog.csdn.net/qiuybing/article/details/39988393

### 服务器突然掉电重启，客户端侧并不知情，此时两者间的 tcp 连接处于什么状态？如果此时客户端向服务器发送数据呢？如何解决这种状态问题？

### MSS 和 MTU 各是什么？二者是什么关系？

> - MSS ，即 Max Segment Size ，最大报文段长度；当基于 tcp 协议发送数据，并且需要对数据进行分段时，该值限制了最大的段字节数；
> - MTU ，即 Max Transport Unit ，最大传输单元；通常由网卡硬件特性规定，表示通过该网卡传输的数据单元的最大字节数；
> - MSS 的值受限于所在机器的 MTU 的限制；例如 MTU 为 1500 字节，那么 MSS 最大只能到 1460 字节；

### 假设机器 A 和 B 的 mss 分别为 1400 和 1600 字节，请问 A 通过 tcp 向 B 发送数据时，是否可以发送长度为 1600 字节的数据？为什么？


### 0x01 每个 TCP 连接最少占用多少内存？

https://zhuanlan.zhihu.com/p/25241630

### 0x01 如何查看 Accept queue 中的内容？

### 0x01 Accept queue 中的连接是按照 FIFO 顺序被取走处理的吗？

https://www.linuxquestions.org/questions/programming-9/linux-tcp-ip-accept-queue-411319/

> - open request
> - accept queue
> - tcp_acceptq_queue 和 tcp_accept


### 0x01 如何杀掉一条 TCP 连接，尤其是针对一些非正常状态的连接？

> 要点：
>
> - 杀掉一个 TCP 连接需要知道相应的 ACK 和 SEQ，然后才可以 reset 连接；
> - 获取 ACK 和 SEQ 的办法：
>     - 被动机制，通过监听匹配的数据包来获取需要的数据 ，代表是 tcpkill ；
>     - 主动机制，通过伪造请求来获取需要的数据，代表是 killcx ；



### 0x01 处于 CLOSE_WAIT 状态的 socket 能够被超时回收么？

> 要点：
>
> - 当被动关闭的一方处于 CLOSE_WAIT 状态时，主动关闭的一方处于 FIN_WAIT2 状态。 那么为什么我们总听说 CLOSE_WAIT 状态过多的故障，但是却相对少听说 FIN_WAIT2 状态过多的故障呢？这是因为 Linux 有一个「tcp_fin_timeout」设置，控制了 FIN_WAIT2 的最大生命周期。坏消息是 CLOSE_WAIT 没有类似的设置，如果不重启进程，那么 CLOSE_WAIT 状态很可能会永远持续下去；好消息是如果 socket 开启了 keepalive 机制，那么可以通过相应的设置来清理无效连接，不过 keepalive 是治标不治本的方法；


### 0x01 处于 FIN_WAIT_2 状态的 socket 多久能够被回收？

> 要点：
>
> - 在该状态的 socket 称作 orphaned socket ，对应的连接称作 orphaned connection ；
> - 由 `net.ipv4.tcp_fin_timeout` 参数进行控制；
> - 默认为 60s ；

背景信息：

> The length of time an orphaned (no longer referenced by any application) connection will remain in the FIN_WAIT_2 state before it is aborted at the local end. 
> While a perfectly valid "receive only" state for an un-orphaned connection, an orphaned connection in FIN_WAIT_2 state could otherwise wait forever for the remote to close its end of the connection.


### 0x01 处于 FIN_WAIT_1 状态的 socket 多久能够被回收？

> 要点：
>
> - 在该状态的 socket 称作 orphaned socket ，对应的连接称作 orphaned connection ；
> - 由 `net.ipv4.tcp_orphan_retries` 参数进行控制，因为 FIN_WAIT_1 状态的维持时间取决于 FIN 的重传；
> - 如果通过 sysctl 查到 tcp_orphan_retries 为 0，那么按照内核中的代码实现，实际等同 于 8 ；
> - 8 次重传会按照 200ms、400ms、800ms、1600ms、3200ms、6400ms、12800ms、25600ms 的时间间隔重发，大约持续 102200ms = 102.2s ；
> - 如果你的系统负载较重，有很多 FIN_WAIT_1 状态的连接，则可以考虑通过降低 tcp_orphan_retries 来解决问题；
> - 可以通过 `net.ipv4.tcp_max_orphans` 限制 orphans (orphaned sockets) 的最大值（一般情况下，不建议降低该值）；
> - 可能原因：最大的可能性是出现了网络故障；

背景信息：

> This value influences the timeout of a locally closed TCP connection, when RTO retransmissions remain unacknowledged.
> The default value is 8.
> If your machine is a loaded WEB server, you should think about lowering this value, such sockets may consume significant resources. Cf. tcp_max_orphans. 


### 0x01 一次完成的 TCP 交互过程？


> 要点：
> 
> - ARP
> - TCP


### 什么是 orphaned sockets ？什么是 orphaned connection ？

> 要点：
>
> - 其实两者是同一个问题的不同描述；
> - orphaned sockets => not attached a FD - 从 fd 角度进行说明
> - orphaned connection => no longer referenced by any application - 从连接角度进行说明
> - each orphan eats up to ~64K of unswappable memory


### 0x01 SYN queue 长度如何计算？

> - 当 kernel version < 2.6.20 时，SYN queue 的长度等于 `net.ipv4.tcp_max_syn_backlog` 的值（对应内核源码中 sysctl_max_syn_backlog 的值）；
> - 当 kernel version >= 2.6.20 时，且 < 4.3 时，SYN queue 的长度取决于
>     - listen 系统调用的 backlog 参数和 `net.ipv4.tcp_max_syn_backlog` 之间的小值，记为 A ；
>     - A 和 8 之间的大值，记为 B ；
>     - 求出比 B + 1 大的最小的 2^N 值，记为 C；
> - C 即计算出的 SYN queue 长度；
> - 当 kernel version >= 4.3 时，SYN queue 的长度等于 `listen(2)` 调用的 backlog 参数（同 accept queue 的长度），而上限值由 `net.core.somaxconn` 控制；


### 0x01 容易导致 SYN queue 满的场景或原因？

> - 与新连接请求（即 SYN 包）到达速率相比，若客户端和服务器之间的 round-trip time（即 RTT）过长（意思就是 SYN->SYN,ACK->ACK 的交互时间过长），则会发生此情况；


### 0x01 Accept queue 长度如何计算？

> - Accept queue 的长度取决于 listen 系统调用的参数 backlog 和 net.core.somaxconn 值，最终取两者中的小值；


### 0x01 容易导致 Accept queue 满的场景或原因？

> - 服务进程本身或者服务器宿主处于忙碌状态，导致进程调用 Accept 获取 completed entries 的速度不够快；


### 0x01 同时开启 tcp_tw_recycle 和 tcp_timestamps 可能遇到的问题以及背后的原因？

> 现象：当位于 NAT 后的多个客户端同时访问外部服务器时，可能出现连接建立不成功的情况；具体表现为客户端发送了 SYN 包给服务器，服务器也收到了，但就是不回复 SYN,ACK 给客户端，从而导致客户端多次重传 SYN ；
> 
> 原因：简单来说，启用 tcp_tw_recycle 机制后，TIME_WAIT 状态的超时时间从 2MSL 变成了 rto 的值，而 rto = (icsk->icsk_rto << 2) - (icsk->icsk_rto >> 1) = 3.5 * icsk->icsk_rto ，其中 icsk->icsk_rto 的值是超时重传的时间，这个值是根据网络情况动态计算的，在网络比较好的情况下，rto 的值会小于 2MSL (即 TCP_TIMEWAIT_LEN），从而达到加速的目的；但是如果在网络情况比较差，也就是说客户端和服务器端往返的时间比较长的情况下，rto 的值有可能会大于 2MSL ，这种情况下反而适得其反，这种情况通常是由客户端引起的。所以在设置 tcp_tw_recycle 的时候要考虑到客户端的情况；
> 设置该参数的主要目的在于（大多数情况）可以及时回收 TIME_WAIT 状态的连接，进而减少系统资源占用。但是 2MSL 变为 rto 后，可能导致出现数据包错乱；比如被动关闭一方的 FIN 包迟迟没有到来，服务器这边会回收这个连接，然后之后的新连接可能会复用这个端口，之后若突然收到了客户端老的 FIN 包，服务器会以为该 FIN 包对应的端口正是刚刚建立的新连接对应的端口，于是服务器就把新连接给干掉了；在设置了 `/proc/sys/net/ipv4/tcp_tw_recycle` 的情况下，触发 recycle 后会清除掉 TCP 四元组信息释放内存，所以没法进行端口判断了，但是基于 IP 判断还是可以的；所以退而求其次：比较目标 IP 的最新更新的时间戳，如果碰到一个具有很老 TSVal 时间戳的数据包过来，服务器会认为这应该是之前很老的数据包的重传，只能忽略它。因此实践中协议采取的策略是：**60 秒内同一个 IP 建立 2 个连接的话，后面一个 SYN 连接的时间戳必须大于之前的 SYN 里面的 TSVal ，否则服务器会认为这是一个老连接的数据包，忽略它**。


### 0x01 如何进行 TIME_WAIT 调优

> 要点：
> 
> - 相关调优参数
>     - net.ipv4.tcp_timestamps
>     - net.ipv4.tcp_tw_reuse
>     - net.ipv4.tcp_tw_recycle
> - tcp_timestamps 是基础，必须开启
> - tcp_tw_reuse - 客户端角色，主动建立连接，主动关闭连接 - outbound
> - tcp_tw_recycle - 服务端角色，被动建立连接，主动关闭连接 - inbound


背景信息：

> RFC 1323 在 TCP Reliability 一节里，引入了 timestamp 的 TCP option ，两个 4 字节的时间戳字段，其中第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到数据的时间。有了这两个时间字段，也就有了后续优化的余地。tcp_tw_reuse 和 tcp_tw_recycle 就依赖这些时间字段。
>
> tcp_tw_reuse 即 reuse TIME_WAIT 状态的连接，应用场景：某一方，需要不断的通过“短连接”连接其他服务器，总是自己先关闭连接，即 TIME_WAIT 在自己这方，关闭后又不断的重新连接对方。那么，当连接被复用了之后，延迟或者重发的数据包到达，新的连接怎么判断，到达的数据是属于复用后的连接，还是复用前的连接呢？那就需要依赖前面提到的两个时间字段了。复用连接后，这条连接的时间被更新为当前的时间，当延迟的数据达到，延迟数据的时间是小于新连接的时间，所以，内核可以通过时间判断出，延迟的数据可以安全的丢弃掉了。**这个配置依赖于连接双方同时对 tcp_timestamps 的支持**。同时这个配置**仅仅影响 outbound 连接**，即做为客户端的角色连接服务端时复用 TIME_WAIT 的 socket 。
>
> tcp_tw_recycle 即销毁掉 TIME_WAIT 状态的连接，应用场景：当开启了这个配置后，内核会快速的回收处于 TIME_WAIT 状态的 socket 连接。多快？不再是 2MSL ，而是一个 RTO（retransmission timeout，数据包重传的 timeout 时间）的时间，这个时间根据 RTT 动态计算出来，但是（一般情况下）远小于 2MSL 。有了这个配置，还是需要保障丢失重传或者延迟的数据包，不会被新的连接所错误的接收（注意，这里不再是复用了，而是之前处于 TIME_WAIT 状态的连接已经被 destroy 掉了，新的连接刚好是和某一个被 destroy 掉的连接使用了相同的五元组而已）。在启用该配置，当一个 socket 连接进入 TIME_WAIT 状态后，内核里会记录包括该 socket 连接对应的五元组中的对方 IP 等在内的一些统计数据，当然也包括从该对方 IP 所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。这个配置**依赖于连接双方对 tcp_timestamps 的支持**。同时这个配置**主要影响到了 inbound 的连接**（对 outbound 的连接也有影响，但是不是复用），即做为服务端角色，客户端连进来，服务端主动关闭了连接，TIME_WAIT 状态的 socket 处于服务端，服务端快速的回收该状态的连接。由此，如果客户端处于 NAT 的网络（多个客户端，同一个 IP 出口的网络环境），如果配置了 tcp_tw_recycle ，就可能在一个 RTO 的时间内，只能有一个客户端和自己连接成功（不同的客户端发包的时间不一致，造成服务端直接把数据包丢弃掉）。


### 0x01 日志 “TCP: time wait bucket table overflow” 说明了什么？

> 要点：
> 
> - 在 TIME_WAIT 套接字数量超过系统 `net.ipv4.tcp_max_tw_buckets` 限制或者内存不足 inet_twsk_alloc 失败时；
> - 上述日志输出在 `/var/log/message` 中；
> - tcp_max_tw_buckets 超限后，主动关闭 socket 的一方将跳过 TIME_WAIT 状态，直接进入 CLOSED，会让 TCP 变得不再可靠；当被动关闭的一方早先发出的延迟包到达后，就可能出现类似下面的问题：
>     - 旧 TCP 连接已经不存在了，系统此时只能返回 RST 包；
>     - 新 TCP 连接被建立起来了，延迟包可能干扰新的连接；
> - 假如 tcp_max_tw_buckets 的值设的太小，否则会导致部分连接没法进入 TIME_WAIT 状态，TCP 连接可能会不正常关闭，数据包会重传；
> - 假如 tcp_max_tw_buckets 的值设置的太大，TIME_WAIT 状态套接字占用的内存可能很大（其实不大）；
> - 该值通常设置大一些比较好，即耗费点内存（空间）一遍给内核足够的时间来清理之前的 TIME_WAIT 状态的套接字；然后再结合其他参数来减小 TIME_WAIT 套接字的影响；这个参数对服务器端和客户端都适用；
> - 系统可能会因此被拖慢（这个说法其实不准确：一般来讲，TIME_WAIT 状态的连接在低于 15w 时不太需要考虑性能问题；若高出，则应该考虑如何进行减少）


背景信息：


> Maximal number of **timewait** sockets held by system simultaneously. If this number is exceeded **time-wait** socket is immediately destroyed and warning is printed. 
> This limit exists only to prevent simple DoS attacks, you must not lower the limit artificially, but rather increase it (probably, after increasing installed memory), if network conditions require more than default value.
>
> ---
> 
> The `tcp_max_tw_buckets` variable tells the system the maximum number of sockets in `TIME-WAIT` to be held simultaneously. If this number is exceeded, the exceeding sockets are destroyed and a warning message is printed to you. The reason for this limit to exist is to get rid of really simple DoS attacks.
>
> The `tcp_max_tw_buckets` variable takes an integer value which tells the system at which point to start destroying **timewait** sockets. The default value is set to **180000**. This may sound much, but it is not. If anything, you should possibly need to increase this value if you start receiving errors due to this setting.
> 
> **Caution**: You should not lower this limit artificially. If you start receiving errors indicating this problem in normal operation, you should instead increase this value if your network requires so. This may lead to the requirement of more memory installed in the machine in question.



### 0x01 日志 “kernel: possible SYN flooding on port 80. Sending cookies.” 说明了什么？

> 要点：
> 
> - 说明设置了 `net.ipv4.tcp_syncookies = 1` ；
> - 说明 SYN Queue 已满，因为只有在 SYN 队列已满的情况下才会触发 SYN cookies 机制；
> - 需要知道 SYN Queue 长度如何计算；
> - SYN cookies 机制的核心就是避免攻击造成的大量构造无用的连接请求块，导致内存耗尽，而无法处理正常的连接请求；
> - 设置 SYN Cookie 就是给每一个请求连接的 IP 地址分配一个 Cookie ，如果短时间内连续收到来自某个 IP 的重复 SYN 报文，就认定是受到了攻击，以后从这个 IP 地址来的包会被一概丢弃；SYN Cookie 依赖于对方使用真实的 IP 地址；


### 0x01 服务器侧出现大量 TIME_WAIT 状态的连接，表明什么？会有何种影响？

> 要点：
> 
> - 服务器侧主动关闭了连接；
> - TIME_WAIT 的存在是为了解决网络的丢包和网络不稳定所带来的其他问题：
>     - 防止前一个连接上延迟的数据包或者丢失重传的数据包，被后面复用的连接错误的接收；
>     - 确保连接方能在时间范围内，关闭自己的连接；
> - TIME_WAIT 会保持 2MSL 时间，大约 2~4 分钟（建议通过 `ss` 命令的 `-o` 选项实际观测具体数值），才最终进入 CLOSED 状态；
> - 在一个连接没有进入到 CLOSED 状态之前，这个连接是不能被重用（因为对应该连接的四元组仍旧存在于 connection table 中）；
> - 若 TIME_WAIT 数量在几百几千的范围，可以忽略其对系统的影响（1 万条 TIME_WAIT 连接也就多消耗 1M 左右的内存）；
> - 大量 TIME_WAIT 状态的连接会占用内存（维护四元组等信息），并导致 CPU 耗费（查询遍历），即传说中的服务器变慢（20w以下应该不需要考虑这个问题）；
> - TIME_WAIT 的数量取决于 `net.ipv4.ip_local_port_range` 和 `net.ipv4.tcp_max_tw_buckets` 中的小值；
> - 若通过调整系统参数使得 TIME_WAIT 时间缩短，则有很高的机率，造成数据错乱，或者短暂性的连接失败；
> - TIME_WAIT 状态的连接不会占用 fd 资源，但会以四元组的形式占用 connection table 中的 slot ；


相关参数（需要了解副作用）

```
# TIME_WAIT 状态的连接重用功能（注意：重用的是 TIME_WAIT 套接字占用的端口号，而不是 TIME_WAIT 套接字的内存等）
net.ipv4.tcp_tw_reuse = 0

# 时间戳选项，默认为 1
# TCP option that can be used to calculate the Round Trip Measurement in a better way 
# than the retransmission timeout method can.
# This should be backwards compatible in almost all circumstances so you could very well 
# turn this on if your host lives on a high speed network. 
# 注：1000mpbs 就算高速网络了
net.ipv4.tcp_timestamps = 0

# TIME_WAIT 状态的连接回收功能，该功能要求 tcp_timestamps 设置为 1 ，单独设置没效果
# 副作用：用来快速回收 TIME_WAIT 连接，但在 NAT 环境下，可能出现由于不同客户端时间戳不同而引发问题
net.ipv4.tcp_tw_recycle = 0

# 若超过此限制，则主动关闭 socket 的一方将不会进入 TIME_WAIT 状态，而直接进入 CLOSED 状态
# 并在系统日志 /var/log/message 里输出 "TCP: time wait bucket table overflow"
net.ipv4.tcp_max_tw_buckets = 131072
```

> 信息补充：
>
>> 限于实际的网络情况，很多用户的客户端没有公网 IP ，只能依赖于 NAT 分享同一个公网 IP ， 这样，由于同一 NAT 下的不同机器的时间戳不一定保证同步，所以就**导致同一个 NAT 过来的数据包的时间戳不能保证单调递增**。这样就打破了 RFC1323 中 PAWS 方法依赖于对端时间戳单调递增的要求。所以就表现为时间戳错乱，导致丢弃时间戳较小的数据包，表现为 "packets rejects in established connections because of timestamp" 的数据不断增加。所以，**在 LVS 中的机器需要关闭 tcp_tw_recycle** 。

> 关于 TIME_WAIT 耗费内存和 CPU 的说明：
>
>> 基本原则：任何你可以看到的数据，内核里都需要有相关的数据结构来保存这个数据；
>> 
>> 对于处于 TIME_WAIT 状态的 socket 来说
>> - 内核里有保存所有连接的一个 hash table ，这个 hash table 里面既包含 TIME_WAIT 状态的连接，也包含其他状态的连接。主要用于有新的数据到来的时候，从这个 hash table 里快速找到这条连接。不同的内核对这个 hash table 的大小设置不同，你可以通过 dmesg 命令去找到你的内核设置的大小：
>> - 还有一个 hash table 用来保存所有的 bound ports ，主要用于可以快速的找到一个可用的端口或者随机端口：
>> - 对于 TIME_WAIT 状态的连接来说，只需要关心结构体 tcp_timewait_sock 跟结构体 inet_bind_socket 所占用的空间大小；
>>
>> 基本原则：每次找一个随机端口还是需要遍历一遍 bound ports 的，必然需要一些 CPU 时间；


### 0x01 dmesg 中的 "TCP established hash table" 和 "TCP bind hash table" 分别是什么？

> 要点：
>
> - "TCP established hash table" 即连接存储哈希表，其中既包含 established 状态的连接，也包含非 established 状态的连接；当有新的数据包发来时，是用来定位查找存活状态的连接的。该哈希表的大小，取决于操作系统内存大小；在系统引导时，会打印出来，dmesg 日志中可以看到；用于维护 TIME-WAIT 状态连接列表中，每一个元素都是一个 tcp_timewait_sock 结构体，其他状态的连接都是 tcp_sock 结构体；
> - "TCP bind hash table" 即绑定端口哈希表，存储绑定端口跟其他参数，用来确保当前端口没有被使用的，比如在 listen 监听时的指定端口，或者连接其他 socket 时，系统动态分配的端口。该哈希表的大小跟连接哈希表大小一样。绑定端口哈希表中的每个元素都是 inet_bind_socket 结构体。每个绑定的端口都对应有一个元素。



实际情况

```
root@ip-172-31-3-170:~# dmesg |grep "TCP"
[    0.656799] TCP established hash table entries: 131072 (order: 8, 1048576 bytes)
[    0.660962] TCP bind hash table entries: 65536 (order: 8, 1048576 bytes)
[    0.664468] TCP: Hash tables configured (established 131072 bind 65536)
[    0.667852] TCP: reno registered
[    1.088294] TCP: cubic registered
[9951455.990583] DCCP: Activated CCID 2 (TCP-like)
root@ip-172-31-3-170:~#
```


### 0x01 服务器侧出现大量 CLOSE_WAIT 状态的连接，表明什么？会有何种影响？

> 要点：
> 
> - 出现在被动关闭的一侧；
> - 主动关闭的一侧会处于 FIN_WAIT_2 状态；
> - 相对特别的情况：
>     - 由于服务端侧处理速度慢，导致客户端认为有超时发生（可能仅仅是业务层面的认为），进而导致业务侧主动关闭该连接；服务器侧可能还在（缓慢的）进行着处理，只是由于各种原因没法及时做出处理响应；从而从服务器侧看，当能够处理该连接时，该连接已处于 CLOSE_WAIT 状态；
>     - 某些语言（例如 python）实现连接池用于复用 TCP 连接，然而由于实现的问题，某些连接虽然处于 ESTABLISHED 状态，但由于长时间没有活跃数据，导致该连接被回收到连接池中，之后业务再次使用该连接时，由于连接已经被回收，故不能够被正常使用，业务侧发起主动连接关闭，导致该连接在连接池中变为 CLOSE_WAIT 状态；
>     - accept 的 backlog 太大，突然遭遇大访问量的话，即便响应速度不慢，也可能出现来不及消费，导致多余的请求还在队列里就被对方关闭了；
> - 相对常见的情况：
>     - 程序中忘记 close 相应的 socket 连接
>     - CPU 处理不过来
>     - 程序一直由于锁或者文件 I/O 等原因睡眠在其它地方
>     - 有死循环发生
>     - 有死锁发生
> - CLOSE_WAIT 是不会自动消失的，并且会占着 fd 等资源；


### 0x01 服务器侧出现大量 SYN_RECV 状态的连接，表明什么？会有何种影响？

> 要点：
> 
> - 收到 SYN 包后发送了 SYN,ACK 包（在正常情况下，服务器端接收到客户端发送的 SYN 包，会分配一个连接请求块，即 request_sock 结构，用于保存连接请求信息，并且发送 SYN,ACK 包给客户端，然后将连接请求块添加到半连接队列中）；
> - 知道 SYN_RECV 原本为瞬态；
> - 知道 SYN_RECV 状态下默认会重传 `net.ipv4.tcp_synack_retries = 5` 次 SYN,ACK 包，以及重传过程大概持续多久（即 SYN timeout 时间）；
> - 知道 SYN_RECV 状态的连接是在 SYN Queue 半连接队列中维护，因此会占用 SYN Queue 半连接队列的槽位；
> - 知道 SYN Queue 的长度如何计算；
> - 知道如何判定 SYN Queue 是否已满；
> - 知道 SYN Queue 满了之后的表现是什么；
> - 知道 SYN_RECV 状态下的连接会占用哪些系统资源，以及对业务影响（在 32bit 系统中，每个处于 SYN_RECV 状态的连接占用大概 80 字节内存，TCP 数据接收、发送缓冲，系统 fd 占用）；
> - 可能的原因：
>     - SYN Flood 攻击原理（被 SYN flood 攻击，攻击者不会进行 ACK 回复），以及防范手段（基于 iptables 临时封 ip 段）；
>     - 由于某些设置（防火墙规则，策略路由等）导致 SYN,ACK 压根没正确发送回去；

辅助命令

```
netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'  # 查看各种 TCP 状态分布
netstat -na > xxx.txt   # 保留现场用
iptables -A INPUT -s  173.0.0.0/8  -p tcp  –dport 80 -j DROP   # 利用 iptables 临时封掉最大嫌疑攻击的 IP 或 IP 号段
```

常见错误信息（/var/log/messages）：

```
Apr 18 11:21:56 web5 kernel: possible SYN flooding on port 80. Sending cookies.
```


相关系统参数（/etc/sysctl.conf）：

```
# 设置为 0 则不进行 SYN,ACK 重试，可以加快回收“半连接”，不会耗光 SYN queue 空间
# 设置为 0 的副作用：网络状况很差时，如果对方没收到第二个握手包，可能连接服务器失败
# 可以只在被 SYN Flood 攻击时临时启用这个参数并设置为 0
# 缩短 SYN Timeout 时间（即 tcp_synack_retries 次重传的总时间）仅在攻击频度不高的情况下有效果
# 
# 如下内容摘抄自文档，实际测试发现超时时间上有出入
# Each retransmission will take aproximately 30-40 seconds. 
# The default value of the tcp_synack_retries variable is 5, and hence the 
# default timeout of passive TCP connections is aproximately 180 seconds.
net.ipv4.tcp_synack_retries = 5


# Each connection retransmission takes aproximately 30-40 seconds. 
# The default setting is 5, which would lead to an aproximate of 180 seconds 
# delay before the connection times out.
net.ipv4.tcp_syn_retries = 6


# 影响半连接队列长度的参数之一（详见具体计算方式）
#
# 以下为某文档中的说明：
# The maximum number of queued connection requests which have still not received 
# an acknowledgement from the connecting client. 
# If this number is exceeded, the kernel will begin dropping requests. 
net.ipv4.tcp_max_syn_backlog = 128


# 当出现半连接队列溢出时，向对方发送 SYN,ACK 时带上 syncookies 
# 调大半连接队列后没必要（但首先要确保半连接队列被正确调大了）
net.ipv4.tcp_syncookies = 0
```



### 0x01 什么情况下 tcp 协议栈（不）自动回复 SYN,ACK 包？

> 要点：
> 
> - 在 **SYN queue 未满**的情况下，收到 SYN 包后，TCP 协议栈自动回复 SYN,ACK 包，之后在收到 ACK 时，根据 Accept queue 状态进行后续处理；
> - 若 **SYN queue 已满**的情况下，收到 SYN 包后，
>     - 若设置 net.ipv4.tcp_syncookies = 0 ，则直接丢弃当前 SYN 包；
>     - 若设置 net.ipv4.tcp_syncookies = 1 ，则
>         - 若 Accept queue 已满，并且 qlen_young 的值大于 1 ，则直接丢弃当前 SYN 包； 
>         - 若 Accept queue 未满，或者 qlen_young 的值未大于 1 （可以简单理解成上限为 len(Accept queue) + 1），则输出 "possible SYN flooding on port %d. Sending cookies.\n"，生成 syncookie 并在 SYN,ACK 回复中带上；
> - 在 **Accept queue 已满**的情况下，收到三次握手最后的 ACK 时，
>     - 若设置了 `tcp_abort_on_overflow = 0` ，则 TCP 协议栈将该连接标记为 acked ，但仍保留在 SYN queue 中，并启动 timer 以便重发 SYN,ACK 包；当 SYN,ACK 的重传次数超过 `net.ipv4.tcp_synack_retries` 设置的值时，再将该连接从 SYN queue 中删除；
>     - 若设置了 `tcp_abort_on_overflow = 1` ，则 TCP 协议栈回复 RST 包，并直接从 SYN queue 中删除该连接信息；



### 0x01 可能导致 SYN -> SYN,ACK -> RST 序列的场景

> 要点：
> 
> - HAProxy 的健康监测（这么实现的好处）
> - 在发送 SYN 后，未收到 SYN,ACK 前，主动关闭当前 socket ，此时由于未成功建立 TCP 连接，故不会发送 FIN 包；之后收到 SYN,ACK 时，底层 TCP 协议栈会直接回复 RST ；



### 0x01 哪些情况下，TCP 协议栈会发送 RST 包给对端？

> - TCPAbortOnSyn
> - TCPAbortOnData
> - TCPAbortOnClose
> - TCPAbortOnMemory
> - TCPAbortOnTimeout 不确定是否发送，因各种计时器 (RTO/PTO/keepalive) 的重传次数超过上限，而关闭连接
> - TCPAbortOnLinger 不确定是否发送，直接从 FIN_WAIT_2 切换到 CLOSED 状态
> - TCPAbortFailed 打算发 RST 但分配 skb 失败
> - TCP 四次挥手时最后一个 ACK 包丢失，若停留在 TIME_WAIT 上的时间被缩短，则主动关闭的一方很快就进入了 CLOSED 状态，如果此时新建一个连接，源随机端口如果被复用，在 connect 发送 SYN 包后，由于被动方仍认为这条连接【五元组】还在等待 ACK ，但是却收到了 SYN ，则被动方会回复 RST ；
> - 在 SYN_SENT 状态下收到 FIN ，会回复 RST
> - socket 处于 FIN_WAIT_2 状态（？）；
> - socket 处于 ESTABLISHED 状态，并且数据包序列号大于 socket 待接收数据序列号（可能情况：由于网络故障+socket 重用等原因收到了之前 socket 连接上的包）；
> - socket 处于 SYN_SENT 状态，数据包 ACK 序列号不正确或者 timestamp 时间戳不正确；
 


### 0x01 可能导致长时间 SYN_SENT 状态的情况？

> 要点：
> 
> - iptables 规则导致，对端收到 SYN 包后直接丢弃
> - 由于对端的系统设置，当 SYN Queue 满了之后，直接 drop 当前 SYN 包
> - NAT 后的多个客户端同时访问外面开启了 tcp_tw_recycle 和 tcp_timestamps 的服务器，此时由于使用的是同一个外部 IP ，且客户端的时间可能不一致，会出现连接建立不成功的情况；服务器侧的表现为，收到了 SYN 包，但由于时间戳不满足单调递增，就是不回复 SYN,ACK 给客户端；
> - 排查 SYN_SENT 问题时需要注意处于该状态的连接是否一直在变化，即是不是同一个连接；因为当 nginx 对大量 upsteam 进行心跳探测的时候，通过 `ss -natp -o` 查看时，能够看到 SYN_SENT 数量基本不变，但具体连接一直在变，这种属于正常情况；



### 0x01 存在哪些会导致出现 TCP “半连接” 的情况？

> 要点：
> 
> - 在 accept queue 已满，但 syn queue 未满时，Client 侧会看到当前连接处于 ESTABLISHED 状态，Server 侧会看到处于 SYN_RECV 状态（非瞬态）
> - 
> - SYN -> (无回应) 后停住（可通过 iptables 规则实现）
> - SYN -> SYN,ACK 后停住（可通过 iptables 规则实现）
> - C/S 中一个突然掉电导致下线




### 0x01 TCP 调参


常见参数调整


```
# vi /etc/sysctl.conf

# 默认为 5，修改为 0 表示不要重发 SYN,ACK
net.ipv4.tcp_synack_retries = 0

# 影响半连接队列长度的参数之一（单独将该参数调大是没有用的）
net.ipv4.tcp_max_syn_backlog = 200000

# 系统最大允许使用的文件句柄数量，同样会限制最大并发连接数，因为连接需要占用文件句柄
fs.file-max = 819200

# 用来应对突发的大并发 connect 请求
net.core.somaxconn = 65536

# 最大的 TCP 数据接收缓冲（字节）
net.core.rmem_max = 1024123000
 
# 最大的 TCP 数据发送缓冲（字节）
net.core.wmem_max = 16777216

# 网络设备接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目
net.core.netdev_max_backlog = 165536

# 本机主动连接其他机器时的端口分配范围
net.ipv4.ip_local_port_range = 10000 65535
```



> 要点：
> 
> -



> 要点：
> 
> -


> 要点：
> 
> -


> 要点：
> 
> -


-------------



netdev_max_backlog 当网卡接收数据包速度快于内核处理速度时，用于保存数据包的队列，即RING BUFFER



参考：

- https://www.frozentux.net/ipsysctl-tutorial/chunkyhtml/tcpvariables.html
- https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt







